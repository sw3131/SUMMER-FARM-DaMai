import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from io import BytesIO

# éœ€è¦ç±»ç›®é™åˆ¶çš„å…³é”®è¯ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
CATEGORY_RESTRICTED_KEYWORDS = {'è‰è“', 'è¥¿ç“œ', 'èŠ’æœ', 'èŠ’'}


def check_dependencies():
    """æ£€æŸ¥å¿…è¦ä¾èµ–åº“æ˜¯å¦å®‰è£…"""
    try:
        import openpyxl
    except ImportError:
        st.error("ç¼ºå°‘å¿…è¦ä¾èµ–åº“ï¼šopenpyxlã€‚è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
        st.code("pip install openpyxl")
        st.stop()


def smart_product_filter(df, search_terms):
    """
    æ™ºèƒ½å•†å“ç­›é€‰ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰ï¼š
    - ç²¾ç¡®åŒ¹é…é¢„è®¾å…³é”®è¯
    - ä»…å½“æœç´¢è¯å®Œå…¨åŒ¹é…é¢„è®¾å…³é”®è¯æ—¶åº”ç”¨ç±»ç›®é™åˆ¶
    """
    # é¢„å¤„ç†
    df_clean = df.assign(
        clean_name=df['å•†å“åç§°'].str.lower().str.strip().fillna(''),
        category_lower=df['ç±»ç›®'].str.lower().str.strip()
    )

    # åˆ†ç¦»å…³é”®è¯ç±»å‹
    restricted_terms = []
    normal_terms = []

    # ç²¾ç¡®åŒ¹é…åˆ¤æ–­
    for term in map(str.strip, map(str, search_terms)):
        term_lower = term.lower()
        if term_lower in {kw.lower() for kw in CATEGORY_RESTRICTED_KEYWORDS}:
            restricted_terms.append(term_lower)
        else:
            normal_terms.append(term_lower)

    # æ„å»ºåŒ¹é…æ¡ä»¶
    conditions = []

    # ç±»ç›®é™åˆ¶æ¡ä»¶ï¼ˆé²œæœç±»ç›® + ç²¾ç¡®å…³é”®è¯åŒ¹é…ï¼‰
    if restricted_terms:
        restr_cond = (df_clean['category_lower'] == 'é²œæœ')
        name_cond = pd.Series(False, index=df.index)
        for term in restricted_terms:
            # ç²¾ç¡®åŒ…å«åŒ¹é…ï¼ˆéå­å­—ç¬¦ä¸²åŒ¹é…ï¼‰
            name_cond |= df_clean['clean_name'].str.contains(
                term, regex=False, case=False
            )
        conditions.append(restr_cond & name_cond)

    # æ™®é€šæ¡ä»¶ï¼ˆå…¨ç±»ç›®æ¨¡ç³ŠåŒ¹é…ï¼‰
    if normal_terms:
        normal_cond = pd.Series(False, index=df.index)
        for term in normal_terms:
            normal_cond |= df_clean['clean_name'].str.contains(
                term, regex=False, case=False
            )
        conditions.append(normal_cond)

    # ç»„åˆæ¡ä»¶ï¼ˆORé€»è¾‘ï¼‰
    if conditions:
        combined_cond = pd.concat(conditions, axis=1).any(axis=1)
        return df[combined_cond]

    return df


def main():
    check_dependencies()

    st.title("ğŸ’¡ æ–°ç‰ˆä½£é‡‘å·¥å…·--å¤§éº¦å›¢é˜Ÿ")
    st.sidebar.header("æ–‡ä»¶ä¸Šä¼ ")

    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    original_file = st.sidebar.file_uploader(
        "1. åŸå§‹æ•°æ®è¡¨ (Excel/CSV)",
        type=["xlsx", "xls", "csv"],
        key="original"
    )

    customer_matching_file = st.sidebar.file_uploader(
        "2. å®¢æˆ·åŒ¹é…è¡¨ (å¯é€‰)",
        type=["xlsx", "xls", "csv"],
        key="customer"
    )

    product_matching_file = st.sidebar.file_uploader(
        "3. å•†å“åŒ¹é…è¡¨ (å¯é€‰)",
        type=["xlsx", "xls", "csv"],
        key="product"
    )

    # å‚æ•°è®¾ç½®
    st.sidebar.header("åˆ†æè®¾ç½®")
    threshold_days = st.sidebar.number_input(
        "æœªè´­ä¹°å¤©æ•°é˜ˆå€¼",
        min_value=1,
        value=30,
        help="è®¾ç½®åˆ¤æ–­å•†å“ä¸æ´»è·ƒçš„æœªè´­ä¹°å¤©æ•°"
    )
    output_filename = st.sidebar.text_input(
        "è¾“å‡ºæ–‡ä»¶å",
        "åˆ†æç»“æœ-å¤§éº¦.xlsx",
        help="è‡ªå®šä¹‰ç»“æœæ–‡ä»¶çš„åç§°"
    )

    if st.sidebar.button("ğŸš€ å¼€å§‹åˆ†æ"):
        if not original_file:
            st.error("âŒ è¯·å…ˆä¸Šä¼ åŸå§‹æ•°æ®è¡¨")
            return

        try:
            # è¯»å–åŸå§‹æ•°æ®
            if original_file.name.endswith(('.xlsx', '.xls')):
                df = pd.read_excel(original_file)
            else:
                df = pd.read_csv(original_file)

            # åˆ—åæ ‡å‡†åŒ–å¤„ç†
            COLUMN_MAPPING = {
                'sku_id': ['sku_id', 'sku'],
                'order_date': ['è®¢å•æ—¥æœŸ', 'ä¸‹å•æ—¶é—´','æ—¶é—´'],
                'BD': ['BD', 'bd_name'],
                'ç±»ç›®': ['ç±»ç›®', 'category']
                'm_id': ['m_id', 'cust_id']
            }

            # è‡ªåŠ¨è¯†åˆ«åˆ—å
            missing_columns = []
            for standard_name, possible_names in COLUMN_MAPPING.items():
                found = [n for n in possible_names if n in df.columns]
                if found:
                    if found[0] != standard_name:
                        df.rename(columns={found[0]: standard_name}, inplace=True)
                else:
                    if standard_name in ['ç±»ç›®', 'order_date']:
                        missing_columns.append(standard_name)

            if missing_columns:
                st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—ï¼š{', '.join(missing_columns)}")
                return

            # å®¢æˆ·åŒ¹é…å¤„ç†
            if customer_matching_file:
                customer_df = pd.read_excel(customer_matching_file) if customer_matching_file.name.endswith(
                    ('.xlsx', '.xls')) else pd.read_csv(customer_matching_file)
                if 'å®¢æˆ·åç§°' not in customer_df.columns:
                    st.error("â›” å®¢æˆ·åŒ¹é…è¡¨å¿…é¡»åŒ…å«ã€Œå®¢æˆ·åç§°ã€åˆ—")
                    return
                df = df[df['å®¢æˆ·åç§°'].isin(customer_df['å®¢æˆ·åç§°'])]
                st.success(f"âœ… å®¢æˆ·ç²¾ç¡®åŒ¹é…å®Œæˆï¼ˆåŒ¹é…åˆ° {len(customer_df)} ä¸ªå®¢æˆ·ï¼‰")

            # å•†å“æ™ºèƒ½åŒ¹é…
            if product_matching_file:
                product_df = pd.read_excel(product_matching_file) if product_matching_file.name.endswith(
                    ('.xlsx', '.xls')) else pd.read_csv(product_matching_file)
                if 'å•†å“åç§°' not in product_df.columns:
                    st.error("â›” å•†å“åŒ¹é…è¡¨å¿…é¡»åŒ…å«ã€Œå•†å“åç§°ã€åˆ—")
                    return

                search_terms = product_df['å•†å“åç§°'].dropna().astype(str).unique()
                original_count = len(df)

                try:
                    df = smart_product_filter(df, search_terms)
                except KeyError as e:
                    st.error(f"âŒ æ•°æ®åˆ—ç¼ºå¤±ï¼š{str(e)}")
                    return

                # ç»Ÿè®¡åŒ¹é…æƒ…å†µ
                matched_restricted = [t for t in search_terms if
                                      t.lower() in {kw.lower() for kw in CATEGORY_RESTRICTED_KEYWORDS}]
                matched_normal = [t for t in search_terms if
                                  t.lower() not in {kw.lower() for kw in CATEGORY_RESTRICTED_KEYWORDS}]

                st.success(f"""
                âœ… å•†å“æ™ºèƒ½åŒ¹é…å®Œæˆï¼š
                - ç±»ç›®æ•æ„Ÿè¯ï¼š{', '.join(matched_restricted) or "æ— "}
                - æ™®é€šå…³é”®è¯ï¼š{', '.join(matched_normal[:3])}{'...' if len(matched_normal) > 3 else ''}
                - ç­›é€‰ç»“æœï¼š{len(df)} æ¡ï¼ˆå‡å°‘ {original_count - len(df)} æ¡ï¼‰
                """)

                if len(df) == 0:
                    st.error("âš ï¸ æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å•†å“ï¼Œè¯·æ£€æŸ¥åŒ¹é…æ¡ä»¶")
                    return

            # æ—¥æœŸå¤„ç†
            df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
            if df['order_date'].isnull().any():
                invalid_count = df['order_date'].isnull().sum()
                st.warning(f"âš ï¸ å‘ç° {invalid_count} æ¡æ— æ•ˆæ—¥æœŸè®°å½•ï¼Œå·²è‡ªåŠ¨æ’é™¤")

            # è®¡ç®—é˜ˆå€¼æ—¥æœŸ
            threshold_date = datetime.now() - timedelta(days=threshold_days)

            # è·å–æœ€æ–°è´­ä¹°è®°å½•
            latest_purchases = (
                df.sort_values('order_date')
                .drop_duplicates(['å®¢æˆ·åç§°', 'å•†å“åç§°'], keep='last')
                .reset_index(drop=True)
            )

            # ç­›é€‰ä¸æ´»è·ƒå•†å“
            inactive_df = latest_purchases[latest_purchases['order_date'] < threshold_date]

            if inactive_df.empty:
                st.balloons()
                st.success(f"ğŸ‰ æ‰€æœ‰å•†å“åœ¨è¿‡å» {threshold_days} å¤©éƒ½æœ‰è´­ä¹°è®°å½•")
                return

            # ç»“æœå¤„ç†
            result_columns = ['å®¢æˆ·åç§°', 'å•†å“åç§°', 'ç±»ç›®', 'sku_id', 'order_date']
            if 'BD' in df.columns:
                result_columns.insert(4, 'BD')
            if 'm_id' in df.columns:
                result_columns.append('m_id')

            inactive_df = inactive_df[result_columns].rename(
                columns={'order_date': 'æœ€åè´­ä¹°æ—¥æœŸ'}
            )

            # æ˜¾ç¤ºç»“æœ
            st.subheader(f"ğŸ“‘ åˆ†æç»“æœï¼ˆå…± {len(inactive_df)} æ¡ä¸æ´»è·ƒå•†å“ï¼‰")
            st.dataframe(
                inactive_df,
                column_config={
                    "æœ€åè´­ä¹°æ—¥æœŸ": st.column_config.DatetimeColumn(
                        format="YYYY-MM-DD"
                    )
                },
                height=400
            )

            # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                inactive_df.to_excel(writer, index=False, sheet_name='ä¸æ´»è·ƒå•†å“')

            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½åˆ†æç»“æœ",
                data=output.getvalue(),
                file_name=output_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="ç‚¹å‡»ä¸‹è½½Excelæ ¼å¼çš„åˆ†ææŠ¥å‘Š"
            )

        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            st.stop()


if __name__ == "__main__":
    main()
